{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "This section documents how to do cross-validation in Scikit-Learn.  Cross validation is our\n",
    "critical model evaluation system.  It tries to simulate how a model would perform on clean \n",
    "data by splitting it into training and testing samples.  To keep things simple we will stick\n",
    "with the basic linear model that we used for monte-carlo examples in class.  Also,\n",
    "the only model fit will be a basic linear regression.  Everything that is done here can\n",
    "easily be extended to any of the models in the Scikit-learn family of ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helpers\n",
    "# Will try to just load what I need on this\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model data generation\n",
    "This model is from the class notes, and generates a simple linear model with M predictors.  We used it to generate overfitting even in linear model space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate linear data experiments\n",
    "def genLinData(N,M,noise):\n",
    "    # y = x_1 + x_2 .. x_M + eps\n",
    "    # X's scaled so the variance of explained part is same order as noise variance (if std(eps) = 1)\n",
    "    sigNoise = np.sqrt(1./M)\n",
    "    X = np.random.normal(size=(N,M),loc=0,scale=sigNoise)\n",
    "    eps = np.random.normal(size=N,loc=0,scale=noise)\n",
    "    y = np.sum(X,axis=1)+eps\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over fitting in one run using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6490379774856974\n",
      "0.2253399639542668\n"
     ]
    }
   ],
   "source": [
    "# Basic overfitting example\n",
    "X, y = genLinData(200,50,1.0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "# Now run regression\n",
    "# print score, which is R-squared (fit)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_train,y_train))\n",
    "print(lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Python for the appropriate simulation of many test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44224466961870573\n",
      "0.1097046822176599\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "nmc = 100\n",
    "X, y = genLinData(200,50,1.0)\n",
    "scoreVec = np.zeros(nmc)\n",
    "for i in range(nmc):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "    # Now run regression\n",
    "    # print score, which is R-squared (fit)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    scoreVec[i] = lr.score(X_test,y_test)\n",
    "print(np.mean(scoreVec))\n",
    "print(np.std(scoreVec))\n",
    "print(np.mean(scoreVec<0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate this by building a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to automate MC experiments\n",
    "def MCtraintest(nmc,X,y,modelObj,testFrac):\n",
    "    trainScore = np.zeros(nmc)\n",
    "    testScore  = np.zeros(nmc)\n",
    "    for i in range(nmc):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=testFrac)\n",
    "        modelObj.fit(X_train,y_train)\n",
    "        trainScore[i] = modelObj.score(X_train,y_train)\n",
    "        testScore[i]  = modelObj.score(X_test,y_test)\n",
    "    return trainScore,testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761162190524635\n",
      "0.02293850535797592\n",
      "0.46753101981207146\n",
      "0.12839692764931585\n"
     ]
    }
   ],
   "source": [
    "nmc = 100\n",
    "lr = LinearRegression()\n",
    "trainS, testS = MCtraintest(nmc,X,y,lr,0.25)\n",
    "print(np.mean(trainS))\n",
    "print(np.std(trainS))\n",
    "print(np.mean(testS))\n",
    "print(np.std(testS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn functions\n",
    "* Scikit-learn has many built in functions for cross validation. \n",
    "* Here are a few of them.\n",
    "\n",
    "### cross-validate\n",
    "* This general functions does many things.  \n",
    "* This first example uses it on a data set, and performs an even more basic cross-validation than we have been doing.  \n",
    "* This is called k-fold cross-validation.\n",
    "* It splits the data set into k parts.  Then trains on k-1 parts, and tests on the remaining 1 part.\n",
    "* This is a very standard cross-validation system\n",
    "* It returns a rich dictionary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = genLinData(200,50,1.0)\n",
    "lr = LinearRegression()\n",
    "CVInfo = cross_validate(lr, X, y, cv=5,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleSplit\n",
    "* ShuffleSplit function can add a randomized train/test split to cross-validate\n",
    "* Here is how you do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = genLinData(200,50,1.0)\n",
    "lr = LinearRegression()\n",
    "shuffle = ShuffleSplit(n_splits=100, test_size=.25, random_state=0)\n",
    "CVInfo = cross_validate(lr, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score\n",
    "* This is a very basic cross validation system\n",
    "* It returns a simple vector of test set (only) scores\n",
    "* Also, uses ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = genLinData(200,50,1.0)\n",
    "lr = LinearRegression()\n",
    "shuffle = ShuffleSplit(n_splits=100, test_size=.25, random_state=0)\n",
    "CVScores = cross_val_score(lr, X, y, cv=shuffle)\n",
    "print(np.mean(CVScores))\n",
    "print(CVScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* Cross-validation is the **gold standard** for testing our models\n",
    "* In most cases we will always use randomized cross validation from now on\n",
    "* This section outlines several ways to do this\n",
    "* See **Scikit-learn** documentation since there are many parts and ways to call the various cross validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
